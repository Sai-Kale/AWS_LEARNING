{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUGNUXvKxFlYy4BMqbXDUE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai-Kale/AWS_LEARNING/blob/master/AWS_S3/s3_notes_a_cloud_guru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjL22wqosFX1"
      },
      "source": [
        "# S3 MasterClass:\n",
        "\n",
        "**AWS:**\n",
        "\n",
        "\n",
        "Personal Projects:\n",
        "1. Wordpress Site\n",
        "2. VPCs (Incl. NAT, bastion, s3 endpoint, elastic IPs, etc,..)\n",
        "3. Route 53 (incl.public and private zones , migrating DNS from external register)\n",
        "4. Cloud front(to S3 and EC2, incl. WAF)\n",
        "5. CLoud Formation\n",
        "6. Lambda\n",
        "7. Elastic Bean Stalk\n",
        "\n",
        "AWS Documentation: https://docs.aws.amazon.com/index.html\n",
        "AWS FAQ's: https://aws.amazon.com/faqs/\n",
        "AWS Whitepapers: Search AWS White papers\n",
        "AWS Playlists on youtube or google aws re invent youtube & check the AWS know your architecture series.\n",
        "AWS Architecture: https://aws.amazon.com/architecture/\n",
        "AWS Answers: https://aws.amazon.com/blogs/aws/aws-answers-architect-more-confidently-effectively-on-aws/\n",
        "AWS Calculator: AWS cost calculator\n",
        "\n",
        "\n",
        "S3 Masterclass:\n",
        "\n",
        "To configure the command line install aws CLI first.\n",
        "Later get Access key and secret key using programmatic access\n",
        "then type -> aws configure on the linux instance and enter the access and secret keys.\n",
        "**type **: aws s3 ls (to list out all the buckets in the account and confirm command is working)\n",
        "\n",
        "\n",
        "S3 provides developers with the highly scalable, durable and HA web storage.\n",
        "Its a object storage with a simple web service and retrieve any amount of information of data anywhere on the web.\n",
        "Objects(files, pictures, videos etc.,..)\n",
        "* Data and associated metadata stored as objects.\n",
        "* its not like a filesystem on windows can't create a operating system on it.\n",
        "* Each objects can be 5TB in size.\n",
        "* Objects are highly durable the probability of losing a is 1 in a 100 billion(achieved as data is replicated across mutiple zones)\n",
        "* HA 99.99% availability\n",
        "* Infinite amount of storage\n",
        "* Its web based so we can upload and download data using web based protocols over the internet.\n",
        "* its secure and we can have different security measures for that.\n",
        "* Its MOSTLY USED in backup and archiving.\n",
        "\t1. Content storage and distribution\n",
        "\t2. Big data & Analytics\n",
        "\t3. Static Web Hosting\n",
        "\t4. DR\n",
        "\n",
        "**Bucket: ** A bucket is a basic contianer in S3 where you store your objects.\n",
        "* Both the objects & buckets are classed as resources. referred within AWS using ARN(each and every resource in AWS has a unique Amazon Resource Name(ARN)\n",
        "* we can upload as many objects as you want in a bucket\n",
        "* But we can create only a 100 buckets by default(can get more by requesting an increase)\n",
        "* Buckets are created in a region.\n",
        "* Buckets have sub resources that basically define how the bucket is configured. A sub resource is something that belongs to another resource and can't exisit on its own.(if main resource is deleted sub resources is deleted as well)\n",
        "**S3 Namespace: **\n",
        "\t* Its universally unique. once created it cant be used again by any other bucket.\n",
        "\t* Bucket name is also universally unique.\n",
        "\t* it can be accessed via virtual or path based URL\n",
        "\t\tVirtual: http://bucket.s3-aws-region.amazonaws.com or http://bucket.s3.amazonaws.com\n",
        "\t\tpath based: http://s3-aws-region.amazonaws.com/path (in path based path comes at last these are depreceated)\n",
        "**Region: **\n",
        "\t* Objects & buckets created  in a particular region never leave that region unless specifically copied over\n",
        "\t* We might choose a region to minimize latency & security issues etc.,..\n",
        "\t* S3 is a key value store.\n",
        "\t\tkey = name of the object, value = that data being stored(0-5TB in size), version ID= A string of data assigned to an object when versioning is enabled.\n",
        "\t\tbucket + key + Version ID helps in unique identification of data. \n",
        "\t* Metadata = Name-value pairs which are used to store information about the object\n",
        "\t* Subresources = resources specifically assigned to an object.(Ex: access control information = policies for controlling access to a resource)\n",
        "**Object Names: **\n",
        "* S3 has a flat structure unlike File System we cant have directories within directories\n",
        "* However directories can be imitated by the use of 'prefixes'\n",
        "\tEx: http://saikumar.s3.amazonaws.com/images/public/thumnails/me.jpg\n",
        "\t\there saikumar is bucket name, images/public/thumnails/me,jpg is object KEY, whereas images/public/thumnails/ is PREFIX looks like directory but not actually one its just a logical nesting.\n",
        "* Objects KEY names can use UTF-8 enconding and cant be longer than 1024 bytes\n",
        "* When naming the bcukets its recomended to used DNS safe naming and characters. If we dont use that we might cant use few features like S3 transfer accelaration etc.,..\n",
        "* Objects can be also tagged i.e project=a , classfication = confidential etc.,.. we can have max 10 tags. They enable fine grain access control.\n",
        "* We can setup Fine grained lifecycle management using tag and also Filtering while using CloudWatch and Cloudtrail Logs.\n",
        "\tObject Tags Limitations:\n",
        "\t1. key can be 128 unicode characters in length & value is 258 characters in length\n",
        "\t2. Keys and values are case sensitive\n",
        "\t3. Each tag must have a unique key\n",
        "\t4. Up to 10 tags per object.\n",
        "**S3 Consistency Model: **\n",
        "1. S3 provides 'strong consistency' for PUTS, LISTS and DELETE of objects.\n",
        "2. After any of these operation are performed any subsequent read request immediately recieves the latest version of object.\n",
        "\t\t->\tPrior to this 2020 it was eventually consistent. bascially it might take some time to replicate.\n",
        "\t\t->\tStrong Consistency is only for Objects and Buckets still have eventual cosistency .\n",
        "\t\t-> Also S3 doesn't have object locking if multiple req are made at the same time, req with the latest time stamp wins\n",
        "**Security: ** \n",
        "* Performs checksums on data and repairs corrupt data using reduntant data.\n",
        "* Cross region replication ticking this option whil creating the bucket provides the ability to improve durability by optionally replicating the data across mutiple regions basically giving amazon permission to replicate across different regions\n",
        "* Versioning if enabled helps us in retrieving the every version of the object every stored even if its deleted for quite some time.\n",
        "* S3 objects are also secure by default. only the bucket & objects owners have access by default. perms and access are given using policies.\n",
        "* S3 encrypts data at rest & transit. All access to S3 can be logged for audit trails.\n",
        "**Making Requests: **\n",
        "* S3 is RESTful web service.\n",
        "* Interact with it over web based protocols like https & http\n",
        "* Requests made via the REST API.(rarely used unless u are a harcore dev)\n",
        "* Interactions usually takes place via the following (that effectively wrap around the REST API)\n",
        "\t1. AWS Management Console\n",
        "\t2. AWS CLI \n",
        "\t3. AWS SDK \n",
        "GET - Download/Read\n",
        "PUT - Upload/Write\n",
        "Delete - Delete\n",
        "\n",
        "**PRICING: **\n",
        "* Utility base pricing meaning pay for what you use.\n",
        "Charge for:\n",
        "\t1. Storage\n",
        "\t2. Requests Made\n",
        "\t3. Data Transfer Pricing\n",
        "\t4. Transfer Acceleration\n",
        "\t5. Mgmt Function.\n",
        "\t\t-> Monitoring metrics(some are free)\n",
        "\t\t-> storage class analysis\n",
        "\t\t-> S3 inventory\n",
        "\t  -> Object tagging.\n",
        "\n",
        "** S3 OBJECT STORAGE CLASSES: **\n",
        "\n",
        "-> When a object is created in S3 we msut specify a stroage class.else by default its taken as Standard. Once object is created you cant change the storage class.\n",
        "* Storage classes are split into 3 types:\n",
        "1.Frequent Accesses Storage:\n",
        "\t* STANDARD:\n",
        "\t\t\tThe default storage class. highly durable, HA with millisecond access to data.\n",
        "\t\t\t\n",
        "\t* REDUCED_REDUNDANCY: \n",
        "\t\t\tSimilar to STANDARD but reduced durability as data isnt replicated as many times. Desinged for non critical and reproducible data.\n",
        "\t\t\t* NOT RECOMENDED as it comes at higher cost that STANDARD\n",
        "2. In-Frequent Accessed Objects:\n",
        "\t* STANDARD_IA:\n",
        "\t\t\tHighly durable& HA, with millisecond latency. Min billable size is 128KB and 30 day retention time. Lower fee than standard but charged a retrieval fee.\n",
        "\t\t\tEx: backup data.\n",
        "\t* ONEZONE_IA: \n",
        "\t\t\tHighly durable with millisecond latency.Difference b/w standard_IA is its stored in only one AZ. however stroage fee is also lower.\n",
        "3. Rarely Accessed Data:\n",
        "\t* GLACIER:\n",
        "\t\t\tA highly durable, cheap stroage class desgined for archive data. where a data portion can be accessible in minutes.\n",
        "\t\t\tMin. billable storage time is 90 days. Data is not avaiable in real time hence it must be restored first.\n",
        "\t* DEEP_ARCHIVE: \n",
        "\t\t\tA hghly durable, extremely cheap. portion of data is retrieved in hours. min. billable storage is 180 days. less than that u cant store here.\n",
        "\t\t\tData isnt avaible real time hence needs to be restored first(might take few hours)\n",
        "4. INTELLIGENT_TIERING:\n",
        "\tMoves the data that isnt accessed from Frequent to In-Frequent after 30 days. However there isnt a data retrival fee when the data is moved to In-Frequent.\n",
        "\tBut small fee is there to tranfer from freq. to in-frequent.\n",
        "\t* Objects must be more than 128 KB in Size.\n",
        "\n",
        "** Lifecycle Policies: **\n",
        "* They help in transistion of objects b/w stroage classes.\n",
        "* A set of rules that can be applied to a group of object or buckets.\n",
        "* 2 types of rules:\n",
        "\t1. Transistion Rule\n",
        "\t\tmove from frequent to in-frequent after x days.\n",
        "\t2. Expiration Rules:\n",
        "\t\tWhen objects are expired.(i.e. deleted)\n",
        "* Ideal for objects having a defined lifecycle.\n",
        "\n",
        "Check this for comaparison: https://aws.amazon.com/s3/storage-classes/\n",
        "\n",
        "**S3 SELECT: **\n",
        "\t* To access any data inside an object(ex: csv file) first we need to GET that object and later fetch that data manually.\n",
        "\t* Instead using select helps us in gettign the required data inside an object Directly.\n",
        "\t* This is also known as \"Query in Place\". This is cheaper and faster as you dont have to download the file.\n",
        "\t* Other tools that are using \"query in place\" in aws is Amazon Athena and Amazon Redshift spectrum. They are designed for data instensive stuff. To get output from multiple objects whereas S3 select is mostly for a single object.\n",
        "\t* Features:\n",
        "\t1. Helps in selective retrieval of data. \n",
        "\t2. Query using standard SQL.(use a subset of standard SQL)\n",
        "\t3. Supports multiple file formats(csv and Json) , compressed(gzip/bzip) as well as non-compresses parquet.\n",
        "\t4. Supports Encryption.\n",
        "\t5. Selective Sacnning. (possible to scan a subset of data by specifying a range of bytes to query. ex: size> 128kb)\n",
        "\t6. Addiontally priced.(charged amount of data scanned and amount of data returned)\n",
        "\t\n",
        "\n",
        "** S3 SECURITY(ACCESS CONTROL): **\n",
        "\n",
        " whats in it:\n",
        "\t*resource & user based policies\n",
        "\t*how s3 evaluates policies\n",
        "\t*which policies should I use?\n",
        "\t*Recap all of them for higher understanding.\n",
        "\n",
        "1.\tPolicies:\n",
        "\t\t> By default all S3 resources are private.\n",
        "\t\t\t- Only the resource owner (the one created ) can access the resource.\n",
        "\t\t\t- the owner can grant access to others by creating a policy.\n",
        "\t\t* Policies come in 2 categories:\n",
        "\t\t    1. policies attached directly to a resource known as resource policies.\n",
        "\t\t\t  2. policies applied directly to IAM users in account know as user policies.\n",
        "\t\t\t* Resource Based Polcies:\n",
        "\t\t\t\t 1. Access Control Lists\n",
        "\t\t\t\t\t-Grant basic read/write perms on objects/buckets to another AWS accounts & pre-defined groups\n",
        "\t\t\t\t\t- use XML schema (a schema based file)\n",
        "\t\t\t\t\t- Consists a list of grants identifying the account/group & their perms.\n",
        "\t\t\t\t2. Bucket Policies:\n",
        "\t\t\t\t\t- Grants perms for the bucket and objects within and outside AWS accounts\n",
        "\t\t\t\t\t- Expresses using JSON.\n",
        "\t\t\t* User Policies:\n",
        "\t\t\t\t\t-Applied directly to users/groups/IAM users by using IAM\n",
        "\t\t\t\t\t- can be used to grant fine grained permission. Expresses by JSON\n",
        "\t\t\t\t\t- Can't be used to grant anonymous access since they apply directly to users.\n",
        "\t\t\t\t\t- Cant be applied to root user.\n",
        "\t\t* Cross Account Access:\n",
        "\t\t\t- Cross Account access is when account A grants permissions to account B to access resources in Account A bucket via bucket policy.\n",
        "\t\t\t\t- EX: Account A admin gives perms to buckets to account B to perform a specific task account B admin delegates the perms to specific users in its accounts via a user policy.\n",
        "\t\n",
        "\t\t  - We can use both the resource based and  user policies.\n",
        "\t\t  - if user and bucket belong to the same account all policies are evaluated at the same time. (same with the object)\n",
        "\t\t\t- if one has Allow and other Deny. Deny wins.\n",
        "\t\t\t- for cross account access its a bit different. refer below\n",
        "\t\t\t\t\thttps://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-auth-workflow-object-operation.html\n",
        "\t\t\t- \t\thttps://docs.aws.amazon.com/AmazonS3/latest/userguide/cors.html\n",
        "\t\t\t\t\thttps://docs.aws.amazon.com/AmazonS3/latest/userguide/acls.html\n",
        "\t\t* In most cases preferred method is to use  user policy or bucket policy as they grant finer perms than ACL's.\n",
        "\t\t* Its down to us which policies to use, ex: all the centralized policies in IAM or bucket policies for exceptions etc.,.\n",
        "\t\t* There are situations where certain policies must be used:\n",
        "\t\t  - ACL's: to manage access to objects NOT owned by bucket owner.\n",
        "\t\t\t- to manage access to individual objects when perms must vary b/w objects. ex: while uploading 1000 objects and want 2 obj to be public.\n",
        "\t\t\t-*to grant permission to a \"s3 log delivery group\" on a bucket. its used S3 to write access logs to that bucket.\n",
        "\t\t  Bucket Policies:\n",
        "\t\t\t- To grant cross account access perms that cant be grant via ACL. ACL is only used Read/Write.\n",
        "\n",
        "\tAccess Control Lists:\n",
        "\t\t* ACL are XML based resource policies used to grant access on both buckets & objects.\n",
        "\t\t* Each bucket has an ACL attached to it as a sub-resources that defines the perms.\n",
        "\t\t* The default ACL grants the resource owner full control to the bucket owner.\n",
        "\t\t* Can be used to grant perms to AWS accounts & pre-defined groups.\n",
        "\t\t* then can only grant only read/write accesss.\n",
        "\t\t\tPre-Defined groups: Authenticated users- All aws accounts, All users - public access, Log delivery group- getting write perms on a bucket to write the acces logs.\n",
        "\t* Bucket and User Policies:\n",
        "\t\tBucket policies are resourced based i.e attached to the bucket resource.\n",
        "\t\t- User policies are attached to the users via IAM\n",
        "\t\t- Bucket policies can grant access to aws accounts or IAM users.\n",
        "\t\t- can grant very fine access. & grant conditional perms\n",
        "\t\t\t- Policy Elements:\n",
        "\t\t\t\t- Prinicipal: The account/user/resource that is allowed access to the actions and resources specified. ( prinicipal : \"*\" = public access )\n",
        "\t\t\t\t- Effect: the effect to be taken when user req the action. either allow or deny\n",
        "\t\t\t\t- Action: the list of perms to allow or deny\n",
        "\t\t\t\t- Resource: the bucket or object to whcih the access applies to. specified by ARN\n",
        "\t\t\t\t- SID: not required for S3. generally used as a description of policy statement.\n",
        "\t\t\t\t* NB(note) -  User based policies do not have prinicipal in the statement because the prinicipal is the user whom execute the policy.\n",
        "\t\t\t* Short Cut: Bucket have \"PEARS\" , users have \"EARS\"\n",
        "\t\t\t- Conditionals: these are additional policy elements that allow you to specify the conditions when a policy is in use, similar to if\n",
        "\t\t\t\tEx: allow a user only if a MFA is done.\n",
        "- S3 Block public access: ( NEEDS MORE CLARITY) check acloudguru access.\n",
        "\t\t- Blocks public access(bucket) even though we have an unrestrictive ACL/Bucket policy. layer around the ACL/bucket policy.\n",
        "\t\t- Block public access(account) blocks access to all the buckets within the account.\n",
        "\t\t\t- Helps override ACL and bucket policies.\n",
        "\t\t\t- can be applied at account , bucket and access point level. but not on the object level.\n",
        "\t\t\t- allows centralized administration of public access\n",
        "\t\t\t   can limit access irrespective of how the resources are created.(governance)\n",
        "\n",
        "\n",
        "\n",
        "S3 CORS(Cross Origin Resource Sharing):\n",
        "\n",
        "https://docs.aws.amazon.com/AmazonS3/latest/userguide/cors.html\n",
        "\t\t\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}